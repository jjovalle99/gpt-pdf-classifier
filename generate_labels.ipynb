{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base64 import b64encode\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_anthropic.chat_models import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "from collections import Counter\n",
    "\n",
    "from src.output_schema import Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"data/\")\n",
    "TEMPERATURE = 0.3\n",
    "OUTPUT_PARSER = JsonOutputParser(pydantic_object=Classification)\n",
    "SYSTEM_MESSAGE = f\"\"\"Please classify the following image into the most appropriate category. If the image does not clearly fit any category or if you're unsure, select 'UNKNOWN'. Here are the categories to choose from:\n",
    "\n",
    "- COVER_PAGE: The image serves as the front page or cover of a document or book.\n",
    "- BLANK_PAGE: The image shows a blank page without text or significant markings.\n",
    "- TEXT_PAGE: The image is predominantly text-based, similar to a book or document page.\n",
    "- IMAGE_PAGE: The image is primarily a photograph or illustration without significant text.\n",
    "- DIAGRAM_PAGE: The image contains diagrams, charts, or graphs, with minimal text.\n",
    "- TEXT_PLUS_IMAGE_PAGE: The image includes both text and significant photographic or illustrative content.\n",
    "- TEXT_PLUS_DIAGRAM_PAGE: The image combines text with diagrams, charts, or graphs.\n",
    "- TABLE_PAGE: The image features tables or spreadsheets.\n",
    "- TEXT_PLUS_TABLE_PAGE: The image includes both text and table(s) or spreadsheet(s).\n",
    "\n",
    "Select the single most fitting category based on the image's content.\n",
    "{OUTPUT_PARSER.get_format_instructions()}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = ChatOpenAI(model=\"gpt-4-vision-preview\", temperature=TEMPERATURE)\n",
    "claude = ChatAnthropic(model=\"claude-3-opus-20240229\", temperature=TEMPERATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_to_base64(img_path):\n",
    "    \"\"\"Encode the image located at img_path to a base64 string.\"\"\"\n",
    "    try:\n",
    "        with img_path.open(\"rb\") as img_file:\n",
    "            return b64encode(img_file.read()).decode(\"utf-8\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the image file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_messages(img_base64, system_message=SYSTEM_MESSAGE):\n",
    "    \"\"\"Prepare messages for inference\"\"\"\n",
    "    human_message = HumanMessage(\n",
    "        content=[\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"},\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    messages = [(\"system\", system_message), human_message]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batches(iterable, n=99):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022-denver-green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = list(DATA_FOLDER.glob(\"*_2022-denver-green-code.jpg\"))\n",
    "file_names = sorted(file_names, key=lambda x: int(x.stem.split('_')[0]))\n",
    "encoded_images = [encode_image_to_base64(img_path=file) for file in file_names]\n",
    "prepared_messages = [prepare_messages(img_base64=img) for img in encoded_images]\n",
    "chain = (gpt | OUTPUT_PARSER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/14 processing...\n",
      "Batch 0/14 processed! sleeping...\n",
      "Batch 0/14 done!\n",
      "Batch 1/14 processing...\n",
      "Batch 1/14 processed! sleeping...\n",
      "Batch 1/14 done!\n",
      "Batch 2/14 processing...\n",
      "Batch 2/14 processed! sleeping...\n",
      "Batch 2/14 done!\n",
      "Batch 3/14 processing...\n",
      "Batch 3/14 processed! sleeping...\n",
      "Batch 3/14 done!\n",
      "Batch 4/14 processing...\n",
      "Batch 4/14 processed! sleeping...\n",
      "Batch 4/14 done!\n",
      "Batch 5/14 processing...\n",
      "Batch 5/14 processed! sleeping...\n",
      "Batch 5/14 done!\n",
      "Batch 6/14 processing...\n",
      "Batch 6/14 processed! sleeping...\n",
      "Batch 6/14 done!\n",
      "Batch 7/14 processing...\n",
      "Batch 7/14 processed! sleeping...\n",
      "Batch 7/14 done!\n",
      "Batch 8/14 processing...\n",
      "Batch 8/14 processed! sleeping...\n",
      "Batch 8/14 done!\n",
      "Batch 9/14 processing...\n",
      "Batch 9/14 processed! sleeping...\n",
      "Batch 9/14 done!\n",
      "Batch 10/14 processing...\n",
      "Batch 10/14 processed! sleeping...\n",
      "Batch 10/14 done!\n",
      "Batch 11/14 processing...\n",
      "Batch 11/14 processed! sleeping...\n",
      "Batch 11/14 done!\n",
      "Batch 12/14 processing...\n",
      "Batch 12/14 processed! sleeping...\n",
      "Batch 12/14 done!\n",
      "Batch 13/14 processing...\n",
      "Batch 13/14 processed! sleeping...\n",
      "Batch 13/14 done!\n"
     ]
    }
   ],
   "source": [
    "results_1 = []\n",
    "batch_size = 20\n",
    "total = len(prepared_messages) // batch_size + 1\n",
    "with tracing_v2_enabled(project_name=\"2022-denver-green\"):\n",
    "    for idx, batch in enumerate(gen_batches(prepared_messages, batch_size)):\n",
    "        print(f\"Batch {idx}/{total} processing...\")\n",
    "        results_1.extend(await chain.abatch(batch, return_exceptions=True))\n",
    "        print(f\"Batch {idx}/{total} processed! sleeping...\")\n",
    "        await asyncio.sleep(60)\n",
    "        print(f\"Batch {idx}/{total} done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(zip(file_names, [c[\"label\"] if isinstance(c, dict) else c for c in results_1]), columns=[\"local_image_path\", \"label\"])\n",
    "df_1.to_csv(\"2022-denver-green-code.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "TEXT_PAGE                                                                                                                                                                                                                                                                                   143\n",
       "TABLE_PAGE                                                                                                                                                                                                                                                                                   34\n",
       "BLANK_PAGE                                                                                                                                                                                                                                                                                   33\n",
       "TEXT_PLUS_TABLE_PAGE                                                                                                                                                                                                                                                                         33\n",
       "COVER_PAGE                                                                                                                                                                                                                                                                                   20\n",
       "TEXT_PLUS_IMAGE_PAGE                                                                                                                                                                                                                                                                          6\n",
       "TEXT_PLUS_DIAGRAM_PAGE                                                                                                                                                                                                                                                                        3\n",
       "Error code: 400 - {'error': {'message': \"You uploaded an unsupported image. Please make sure your image is below 20 MB in size and is of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\", 'type': 'invalid_request_error', 'param': None, 'code': 'sanitizer_server_error'}}      1\n",
       "Error code: 400 - {'error': {'message': \"You uploaded an unsupported image. Please make sure your image is below 20 MB in size and is of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\", 'type': 'invalid_request_error', 'param': None, 'code': 'sanitizer_server_error'}}      1\n",
       "Error code: 400 - {'error': {'message': \"You uploaded an unsupported image. Please make sure your image is below 20 MB in size and is of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\", 'type': 'invalid_request_error', 'param': None, 'code': 'sanitizer_server_error'}}      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20201119Complete_Denver_Zoning_Code_updated11122020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = list(DATA_FOLDER.glob(\"*_20201119Complete_Denver_Zoning_Code_updated11122020.png\"))\n",
    "file_names = sorted(file_names, key=lambda x: int(x.stem.split('_')[0]))\n",
    "encoded_images = [encode_image_to_base64(img_path=file) for file in file_names]\n",
    "prepared_messages = [prepare_messages(img_base64=img) for img in encoded_images]\n",
    "chain = (gpt | OUTPUT_PARSER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/26 processing...\n",
      "Batch 0/26 processed! sleeping...\n",
      "Batch 0/26 done!\n",
      "Batch 1/26 processing...\n",
      "Batch 1/26 processed! sleeping...\n",
      "Batch 1/26 done!\n",
      "Batch 2/26 processing...\n",
      "Batch 2/26 processed! sleeping...\n",
      "Batch 2/26 done!\n",
      "Batch 3/26 processing...\n",
      "Batch 3/26 processed! sleeping...\n",
      "Batch 3/26 done!\n",
      "Batch 4/26 processing...\n",
      "Batch 4/26 processed! sleeping...\n",
      "Batch 4/26 done!\n",
      "Batch 5/26 processing...\n",
      "Batch 5/26 processed! sleeping...\n"
     ]
    }
   ],
   "source": [
    "results_2 = []\n",
    "batch_size = 20\n",
    "total = len(prepared_messages) // batch_size + 1\n",
    "with tracing_v2_enabled(project_name=\"20201119Complete_Denver_Zoning_Code_updated11122020\"):\n",
    "    for idx, batch in enumerate(gen_batches(prepared_messages, batch_size), start=1):\n",
    "\n",
    "        print(f\"Batch {idx}/{total} processing...\")\n",
    "\n",
    "        tmp = await chain.abatch(batch, return_exceptions=True)\n",
    "\n",
    "        count = Counter([c[\"label\"] if isinstance(c, dict) else c for c in tmp])\n",
    "        total_strings = sum(count[key] for key in count if isinstance(key, str))\n",
    "        if total_strings < batch_size - 1:\n",
    "            print(f\"Number of errors: {batch_size - total_strings}\")\n",
    "            break\n",
    "\n",
    "\n",
    "        results_2.extend(tmp)\n",
    "\n",
    "        print(f\"Batch {idx}/{total} processed! sleeping...\")\n",
    "        await asyncio.sleep(60)\n",
    "\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "# List name, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
